{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tutorial 2",
   "id": "447fa4983c0b3f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise 4-7\n",
   "id": "2f266bac81d59774"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:03:04.554763Z",
     "start_time": "2025-04-01T13:03:04.531874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "from GridWorld import GridWorld\n",
    "from Bot import Bot"
   ],
   "id": "a58a6a336e716f73",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:03:05.340367Z",
     "start_time": "2025-04-01T13:03:05.331582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "w, h = 4, 4 # grid size\n",
    "bot = Bot(env=GridWorld(w, h), T = 3)\n",
    "print(bot.env) # draw the grid\n"
   ],
   "id": "e52a33f0ee6a3d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3 \n",
      "0   G   -   -   -   \n",
      "1   -   -   -   -   \n",
      "2   -   -   -   -   \n",
      "3   -   -   -   G   \n",
      "   \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:03:11.645596Z",
     "start_time": "2025-04-01T13:03:11.632807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy_thresh = .001\n",
    "gamma = 1\n",
    "\n",
    "# perform iterative policy evaluation\n",
    "v = bot.iterative_policy_evaluation(accuracy_thresh, gamma)\n",
    "print(\"Initial policy (all actions are equally probable\")\n",
    "pprint(bot.policy)\n",
    "print(\"Value estimations:\", v)\n",
    "print()\n"
   ],
   "id": "fe886dbca50f4838",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial policy (all actions are equally probable\n",
      "{(0, 0): {(0, 1): 0.5, (1, 0): 0.5},\n",
      " (0, 1): {(0, -1): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (0, 2): {(0, -1): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (0, 3): {(0, -1): 0.5, (1, 0): 0.5},\n",
      " (1, 0): {(-1, 0): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (1, 1): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (1, 2): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (1, 3): {(-1, 0): 0.3333333333333333,\n",
      "          (0, -1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (2, 0): {(-1, 0): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (2, 1): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (2, 2): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (2, 3): {(-1, 0): 0.3333333333333333,\n",
      "          (0, -1): 0.3333333333333333,\n",
      "          (1, 0): 0.3333333333333333},\n",
      " (3, 0): {(-1, 0): 0.5, (0, 1): 0.5},\n",
      " (3, 1): {(-1, 0): 0.3333333333333333,\n",
      "          (0, -1): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333},\n",
      " (3, 2): {(-1, 0): 0.3333333333333333,\n",
      "          (0, -1): 0.3333333333333333,\n",
      "          (0, 1): 0.3333333333333333},\n",
      " (3, 3): {(-1, 0): 0.5, (0, -1): 0.5}}\n",
      "Value estimations: [0, -2.333333333333333, -2.888888888888889, -3.0, -2.333333333333333, -2.833333333333333, -3.0, -2.888888888888889, -2.888888888888889, -3.0, -2.833333333333333, -2.3333333333333335, -3.0, -2.888888888888889, -2.333333333333333, 0]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:03:15.144338Z",
     "start_time": "2025-04-01T13:03:15.131332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(bot.env) # draw the grid\n",
    "\n",
    "# set the probabilities in the policy from uniform probs to all either 0 or 1\n",
    "bot.hardline_policy()\n",
    "# perform policy iteration to get the optimal policy\n",
    "v = bot.policy_iteration(accuracy_thresh, gamma)\n",
    "print(\"Policy after policy iteration\")\n",
    "pprint(bot.policy)\n",
    "print(\"Value estimations:\", v)\n",
    "print()\n"
   ],
   "id": "86b9b6508ed9fffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration\n",
      "Iteration 1\n",
      "State (0, 1): Better action found. (1, 0) ==> (0, -1)\n",
      "State (0, 2): Better action found. (0, 1) ==> (0, -1)\n",
      "State (0, 3): Better action found. (1, 0) ==> (0, -1)\n",
      "State (1, 0): Better action found. (0, 1) ==> (-1, 0)\n",
      "State (1, 2): Better action found. (-1, 0) ==> (0, -1)\n",
      "State (2, 0): Better action found. (0, 1) ==> (-1, 0)\n",
      "State (3, 0): Better action found. (-1, 0) ==> (0, 1)\n",
      "State (3, 2): Better action found. (-1, 0) ==> (0, 1)\n",
      "State (3, 3): Better action found. (-1, 0) ==> (0, -1)\n",
      "\n",
      "Iteration 2\n",
      "State (3, 1): Better action found. (0, -1) ==> (0, 1)\n",
      "\n",
      "Iteration 3\n",
      "Policy Is Stable. Returning ...\n",
      "\n",
      "Policy after policy iteration\n",
      "{(0, 0): {(0, 1): 1, (1, 0): 0},\n",
      " (0, 1): {(0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (0, 2): {(0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (0, 3): {(0, -1): 1, (1, 0): 0},\n",
      " (1, 0): {(-1, 0): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 1): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 2): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 3): {(-1, 0): 0, (0, -1): 0, (1, 0): 1},\n",
      " (2, 0): {(-1, 0): 1, (0, 1): 0, (1, 0): 0},\n",
      " (2, 1): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (2, 2): {(-1, 0): 0, (0, -1): 0, (0, 1): 1, (1, 0): 0},\n",
      " (2, 3): {(-1, 0): 0, (0, -1): 0, (1, 0): 1},\n",
      " (3, 0): {(-1, 0): 0, (0, 1): 1},\n",
      " (3, 1): {(-1, 0): 0, (0, -1): 0, (0, 1): 1},\n",
      " (3, 2): {(-1, 0): 0, (0, -1): 0, (0, 1): 1},\n",
      " (3, 3): {(-1, 0): 0, (0, -1): 1}}\n",
      "Value estimations: [0, -1, -2, -3, -1, -2, -3, -2, -2, -3, -2, -1, -3, -2, -1, 0]\n",
      "\n",
      "    0   1   2   3 \n",
      "0   G   -   -   -   \n",
      "1   -   -   -   -   \n",
      "2   -   -   -   -   \n",
      "3   -   -   -   G   \n",
      "   \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:03:16.467508Z",
     "start_time": "2025-04-01T13:03:16.457251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(bot.env) # draw the grid\n",
    "\n",
    "# perform value iteration for show\n",
    "# first reset the policy to random hardline probabilities\n",
    "print(\"... resetting policy ...\")\n",
    "bot.init_policy(hardline=True)\n",
    "v = bot.value_iteration(accuracy_thresh, gamma)\n",
    "print(\"Final policy after value iteration\")\n",
    "pprint(bot.policy)\n",
    "print(\"Value estimations:\", v)\n",
    "print()\n"
   ],
   "id": "44763e8056625ec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... resetting policy ...\n",
      "Value Iteration\n",
      "State (0, 0): Best action = (0, 1)\n",
      "State (0, 1): Best action = (0, -1)\n",
      "State (0, 2): Best action = (0, -1)\n",
      "State (0, 3): Best action = (0, -1)\n",
      "State (1, 0): Best action = (-1, 0)\n",
      "State (1, 1): Best action = (0, -1)\n",
      "State (1, 2): Best action = (0, -1)\n",
      "State (1, 3): Best action = (0, -1)\n",
      "State (2, 0): Best action = (-1, 0)\n",
      "State (2, 1): Best action = (0, -1)\n",
      "State (2, 2): Best action = (0, -1)\n",
      "State (2, 3): Best action = (1, 0)\n",
      "State (3, 0): Best action = (0, 1)\n",
      "State (3, 1): Best action = (0, -1)\n",
      "State (3, 2): Best action = (0, 1)\n",
      "State (3, 3): Best action = (0, -1)\n",
      "\n",
      "Final policy after value iteration\n",
      "{(0, 0): {(0, 1): 1, (1, 0): 0},\n",
      " (0, 1): {(0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (0, 2): {(0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (0, 3): {(0, -1): 1, (1, 0): 0},\n",
      " (1, 0): {(-1, 0): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 1): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 2): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (1, 3): {(-1, 0): 0, (0, -1): 1, (1, 0): 0},\n",
      " (2, 0): {(-1, 0): 1, (0, 1): 0, (1, 0): 0},\n",
      " (2, 1): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (2, 2): {(-1, 0): 0, (0, -1): 1, (0, 1): 0, (1, 0): 0},\n",
      " (2, 3): {(-1, 0): 0, (0, -1): 0, (1, 0): 1},\n",
      " (3, 0): {(-1, 0): 0, (0, 1): 1},\n",
      " (3, 1): {(-1, 0): 0, (0, -1): 1, (0, 1): 0},\n",
      " (3, 2): {(-1, 0): 0, (0, -1): 0, (0, 1): 1},\n",
      " (3, 3): {(-1, 0): 0, (0, -1): 1}}\n",
      "Value estimations: [0, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, 0]\n",
      "\n",
      "    0   1   2   3 \n",
      "0   G   -   -   -   \n",
      "1   -   -   -   -   \n",
      "2   -   -   -   -   \n",
      "3   -   -   -   G   \n",
      "   \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b3b53812354e510"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
