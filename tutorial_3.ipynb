{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tutorial 3",
   "id": "6a378ea508dd6648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:25:17.498366Z",
     "start_time": "2025-05-05T15:25:17.495755Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e3d8c7dde738abcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise 2\n",
    "Off-policy MC control\n",
    "\n",
    "\n"
   ],
   "id": "e26800bf27e47749"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:25:17.605242Z",
     "start_time": "2025-05-05T15:25:17.504682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import MonteCarlo\n",
    "from MonteCarlo import test_grid_world, test_frozen_lake"
   ],
   "id": "c4d7249ba2853a2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing on GridWorld",
   "id": "6e4ffb1d38f95383"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:25:17.909373Z",
     "start_time": "2025-05-05T15:25:17.735506Z"
    }
   },
   "cell_type": "code",
   "source": "MonteCarlo.test_grid_world()",
   "id": "341352e666ded5dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the environment looks like:\n",
      "   0  1  2  3\n",
      "0  G  -  -  -\n",
      "1  -  -  -  -\n",
      "2  -  S  -  -\n",
      "3  -  -  -  G\n",
      "\n",
      "Now we run some episodes and see what we get (before optimizing the policy):\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -3\n",
      "Mean reward: -18.975\n",
      "Mean time-step of termination: 17.975\n",
      "\n",
      "##### Performing policy control #####\n",
      "\n",
      "Iteration 0\n",
      "Iteration 500\n",
      "Policy after policy control:\n",
      "Current policy\n",
      " o   ←   ←   ←  \n",
      " ↑   ↓   →   ↓  \n",
      " ↑   →   ↓   ↓  \n",
      " →   →   →   o  \n",
      "\n",
      "{(0, 0): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (0, 1): {(-1, 0): 0.025, (0, -1): 0.925, (0, 1): 0.025, (1, 0): 0.025},\n",
      " (0, 2): {(-1, 0): 0.025, (0, -1): 0.925, (0, 1): 0.025, (1, 0): 0.025},\n",
      " (0, 3): {(-1, 0): 0.025, (0, -1): 0.925, (0, 1): 0.025, (1, 0): 0.025},\n",
      " (1, 0): {(-1, 0): 0.925, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.025},\n",
      " (1, 1): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.925},\n",
      " (1, 2): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.925, (1, 0): 0.025},\n",
      " (1, 3): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.925},\n",
      " (2, 0): {(-1, 0): 0.925, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.025},\n",
      " (2, 1): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.925, (1, 0): 0.025},\n",
      " (2, 2): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.925},\n",
      " (2, 3): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.025, (1, 0): 0.925},\n",
      " (3, 0): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.925, (1, 0): 0.025},\n",
      " (3, 1): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.925, (1, 0): 0.025},\n",
      " (3, 2): {(-1, 0): 0.025, (0, -1): 0.025, (0, 1): 0.925, (1, 0): 0.025},\n",
      " (3, 3): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0}}\n",
      "\n",
      "\n",
      "Make more test runs after policy control:\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -3\n",
      "Mean reward: -3.0\n",
      "Mean time-step of termination: 2.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:27:33.155558Z",
     "start_time": "2025-05-05T15:27:33.149766Z"
    }
   },
   "cell_type": "code",
   "source": "import Bot",
   "id": "5eb7aa469c25dcc8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise 4",
   "id": "cf688d35255fb82a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:42:05.921462Z",
     "start_time": "2025-05-05T15:42:04.812513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MonteCarlo import test_windy_world\n",
    "test_windy_world()"
   ],
   "id": "fd8857a9e7ca9824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the environment looks like:\n",
      "    0   1   2   3\n",
      "0   S  ↑↑   ↑   o\n",
      "1   o  ↑↑   ↑   o\n",
      "2   o  ↑↑   G   o\n",
      "3   o  ↑↑   ↑   o\n",
      "\n",
      "Now we run some episodes and see what we get (before optimizing the policy):\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -11\n",
      "Mean reward: -88.021\n",
      "Mean time-step of termination: 87.021\n",
      "\n",
      "##### Performing policy control #####\n",
      "\n",
      "Iteration 0\n",
      "Iteration 500\n",
      "Policy after policy control:\n",
      "Current policy\n",
      " →   →   →   ↓  \n",
      " ↓   ↓   →   ↓  \n",
      " →   ←   o   ↓  \n",
      " →   ←   ↓   ←  \n",
      "\n",
      "{(0, 0): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (0, 1): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (0, 2): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (0, 3): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.125, (1, 0): 0.625},\n",
      " (1, 0): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.125, (1, 0): 0.625},\n",
      " (1, 1): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.125, (1, 0): 0.625},\n",
      " (1, 2): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (1, 3): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.125, (1, 0): 0.625},\n",
      " (2, 0): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (2, 1): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (2, 2): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (2, 3): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.125, (1, 0): 0.625},\n",
      " (3, 0): {(-1, 0): 0.125, (0, -1): 0.125, (0, 1): 0.625, (1, 0): 0.125},\n",
      " (3, 1): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (3, 2): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (3, 3): {(-1, 0): 0.125, (0, -1): 0.625, (0, 1): 0.125, (1, 0): 0.125}}\n",
      "\n",
      "\n",
      "Make more test runs after policy control:\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -7\n",
      "Mean reward: -7.0\n",
      "Mean time-step of termination: 6.0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise 5",
   "id": "7fd66e433597ce71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:42:31.949320Z",
     "start_time": "2025-05-05T15:42:30.863586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MonteCarlo import test_cliff_walking\n",
    "test_cliff_walking()"
   ],
   "id": "4192b79b0dc952b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the environment looks like:\n",
      "   0  1  2  3  4\n",
      "0  -  -  -  -  -\n",
      "1  S  X  X  X  G\n",
      "2  -  -  -  -  -\n",
      "3  -  -  -  -  -\n",
      "\n",
      "Now we run some episodes and see what we get (before optimizing the policy):\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -6\n",
      "Mean reward: -2223.919\n",
      "Mean time-step of termination: 84.816\n",
      "\n",
      "##### Performing policy control #####\n",
      "\n",
      "Iteration 0\n",
      "Iteration 500\n",
      "Policy after policy control:\n",
      "Current policy\n",
      " ↓   ↓   ↓   ↓   ↓  \n",
      " ↓   →   ↓   ↑   o  \n",
      " ↓   ↓   ↓   →   ↑  \n",
      " →   →   →   →   ↑  \n",
      "\n",
      "{(0, 0): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (0, 1): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (0, 2): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (0, 3): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (0, 4): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (1, 0): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (1, 1): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (1, 2): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (1, 3): {(-1, 0): 0.25, (0, -1): 0.25, (0, 1): 0.25, (1, 0): 0.25},\n",
      " (1, 4): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (2, 0): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (2, 1): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (2, 2): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.55},\n",
      " (2, 3): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.55, (1, 0): 0.15},\n",
      " (2, 4): {(-1, 0): 0.55, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.15},\n",
      " (3, 0): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.55, (1, 0): 0.15},\n",
      " (3, 1): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.55, (1, 0): 0.15},\n",
      " (3, 2): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.55, (1, 0): 0.15},\n",
      " (3, 3): {(-1, 0): 0.15, (0, -1): 0.15, (0, 1): 0.55, (1, 0): 0.15},\n",
      " (3, 4): {(-1, 0): 0.55, (0, -1): 0.15, (0, 1): 0.15, (1, 0): 0.15}}\n",
      "\n",
      "\n",
      "Make more test runs after policy control:\n",
      "Performing 1000 test runs ...\n",
      "Best reward: -8\n",
      "Mean reward: -8.0\n",
      "Mean time-step of termination: 7.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exercise 6",
   "id": "3e37446874770fb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T15:43:36.677057Z",
     "start_time": "2025-05-05T15:43:24.001969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MonteCarlo import test_frozen_lake\n",
    "test_frozen_lake()"
   ],
   "id": "ce15578e1cb13673",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the environment looks like:\n",
      "   0  1  2  3\n",
      "0  S  -  -  -\n",
      "1  -  H  -  H\n",
      "2  -  -  -  H\n",
      "3  H  -  -  G\n",
      "\n",
      "Now we run some episodes and see what we get (before optimizing the policy):\n",
      "Performing 1000 test runs ...\n",
      "Best reward: 1\n",
      "Mean reward: 0.02\n",
      "Mean time-step of termination: 6.154\n",
      "\n",
      "##### Performing policy control #####\n",
      "\n",
      "Iteration 0\n",
      "Iteration 500\n",
      "Iteration 1000\n",
      "Iteration 1500\n",
      "Iteration 2000\n",
      "Iteration 2500\n",
      "Iteration 3000\n",
      "Iteration 3500\n",
      "Iteration 4000\n",
      "Iteration 4500\n",
      "Iteration 5000\n",
      "Iteration 5500\n",
      "Iteration 6000\n",
      "Iteration 6500\n",
      "Iteration 7000\n",
      "Iteration 7500\n",
      "Iteration 8000\n",
      "Iteration 8500\n",
      "Iteration 9000\n",
      "Iteration 9500\n",
      "Policy after policy control:\n",
      "Current policy\n",
      " ↓   ↑   ←   ↑  \n",
      " ←   o   ←   o  \n",
      " ↑   ↓   ←   o  \n",
      " o   ↓   →   o  \n",
      "\n",
      "{(0, 0): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.7749999999999999},\n",
      " (0, 1): {(-1, 0): 0.7749999999999999,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (0, 2): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.7749999999999999,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (0, 3): {(-1, 0): 0.7749999999999999,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (1, 0): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.7749999999999999,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (1, 1): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (1, 2): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.7749999999999999,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (1, 3): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (2, 0): {(-1, 0): 0.7749999999999999,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (2, 1): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.7749999999999999},\n",
      " (2, 2): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.7749999999999999,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.075},\n",
      " (2, 3): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (3, 0): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0},\n",
      " (3, 1): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.075,\n",
      "          (1, 0): 0.7749999999999999},\n",
      " (3, 2): {(-1, 0): 0.075,\n",
      "          (0, -1): 0.075,\n",
      "          (0, 1): 0.7749999999999999,\n",
      "          (1, 0): 0.075},\n",
      " (3, 3): {(-1, 0): 0, (0, -1): 0, (0, 1): 0, (1, 0): 0}}\n",
      "\n",
      "\n",
      "Make more test runs after policy control:\n",
      "Performing 1000 test runs ...\n",
      "Best reward: 1\n",
      "Mean reward: 0.316\n",
      "Mean time-step of termination: 24.715\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
